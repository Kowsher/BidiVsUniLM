{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ac762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in using your Hugging Face token\n",
    "login(\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f89ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets  = load_dataset(\"glue\", 'rte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cff02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "#config.num_labels=2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers.activations import ACT2FN\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to('cuda')\n",
    "\n",
    "import RoCoFT\n",
    "\n",
    "RoCoFT.PEFT(model, method='column', rank=3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704a1179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 277/277 [00:00<00:00, 8412.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "col_to_delete = ['sentence1','sentence2']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    prompts = [\n",
    "        f\"Premise: {premise} Hypothesis: {hypothesis} \"\n",
    "        f\"Does the premise imply the hypothesis? Answer 'yes' or 'no'.\"\n",
    "        for premise, hypothesis in zip(examples[\"sentence1\"], examples[\"sentence2\"])\n",
    "    ]\n",
    "    return tokenizer(prompts, padding = False, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cd4cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS]Premise: The international humanitarian aid organization, Doctors Without Borders/Medecins Sans Frontieres (MSF), continues to treat victims of violence in all locations where it is present in Darfur. Hypothesis: Doctors Without Borders is an international aid organization. Does the premise imply the hypothesis? Answer 'yes' or 'no'.[SEP]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['validation']['input_ids'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41af8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps= 2,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.00,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    logging_steps=25,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da6eee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2340/2340 35:07, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.644900</td>\n",
       "      <td>0.726659</td>\n",
       "      <td>0.464258</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.448537</td>\n",
       "      <td>0.483755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.450400</td>\n",
       "      <td>0.719041</td>\n",
       "      <td>0.486331</td>\n",
       "      <td>0.487242</td>\n",
       "      <td>0.474383</td>\n",
       "      <td>0.480144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.437200</td>\n",
       "      <td>0.715708</td>\n",
       "      <td>0.476865</td>\n",
       "      <td>0.481674</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.469314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.389600</td>\n",
       "      <td>0.699092</td>\n",
       "      <td>0.469216</td>\n",
       "      <td>0.477125</td>\n",
       "      <td>0.447137</td>\n",
       "      <td>0.490975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>0.695534</td>\n",
       "      <td>0.493246</td>\n",
       "      <td>0.494353</td>\n",
       "      <td>0.477524</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.407900</td>\n",
       "      <td>0.691492</td>\n",
       "      <td>0.544661</td>\n",
       "      <td>0.541331</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.548736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.692165</td>\n",
       "      <td>0.493903</td>\n",
       "      <td>0.495425</td>\n",
       "      <td>0.467910</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.358800</td>\n",
       "      <td>0.688247</td>\n",
       "      <td>0.508821</td>\n",
       "      <td>0.508653</td>\n",
       "      <td>0.507604</td>\n",
       "      <td>0.512635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.349000</td>\n",
       "      <td>0.695716</td>\n",
       "      <td>0.551674</td>\n",
       "      <td>0.526142</td>\n",
       "      <td>0.468799</td>\n",
       "      <td>0.545126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.346000</td>\n",
       "      <td>0.691935</td>\n",
       "      <td>0.535868</td>\n",
       "      <td>0.532260</td>\n",
       "      <td>0.514809</td>\n",
       "      <td>0.523466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.330500</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.549530</td>\n",
       "      <td>0.547422</td>\n",
       "      <td>0.538606</td>\n",
       "      <td>0.541516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>0.690718</td>\n",
       "      <td>0.565503</td>\n",
       "      <td>0.562297</td>\n",
       "      <td>0.552598</td>\n",
       "      <td>0.555957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.291200</td>\n",
       "      <td>0.685829</td>\n",
       "      <td>0.557057</td>\n",
       "      <td>0.556311</td>\n",
       "      <td>0.555950</td>\n",
       "      <td>0.559567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.277100</td>\n",
       "      <td>0.714157</td>\n",
       "      <td>0.550274</td>\n",
       "      <td>0.537358</td>\n",
       "      <td>0.497471</td>\n",
       "      <td>0.523466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.291100</td>\n",
       "      <td>0.687259</td>\n",
       "      <td>0.569238</td>\n",
       "      <td>0.569042</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.566787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.240300</td>\n",
       "      <td>0.686608</td>\n",
       "      <td>0.605660</td>\n",
       "      <td>0.600831</td>\n",
       "      <td>0.598951</td>\n",
       "      <td>0.606498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.255100</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.522868</td>\n",
       "      <td>0.512705</td>\n",
       "      <td>0.442047</td>\n",
       "      <td>0.494585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.219800</td>\n",
       "      <td>0.681533</td>\n",
       "      <td>0.615791</td>\n",
       "      <td>0.614059</td>\n",
       "      <td>0.609492</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.230500</td>\n",
       "      <td>0.682498</td>\n",
       "      <td>0.621262</td>\n",
       "      <td>0.614922</td>\n",
       "      <td>0.612866</td>\n",
       "      <td>0.620939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.163100</td>\n",
       "      <td>0.749104</td>\n",
       "      <td>0.617341</td>\n",
       "      <td>0.593721</td>\n",
       "      <td>0.564040</td>\n",
       "      <td>0.581227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.141800</td>\n",
       "      <td>0.743803</td>\n",
       "      <td>0.593376</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.559277</td>\n",
       "      <td>0.570397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.128800</td>\n",
       "      <td>0.695978</td>\n",
       "      <td>0.597435</td>\n",
       "      <td>0.596335</td>\n",
       "      <td>0.596247</td>\n",
       "      <td>0.599278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.003200</td>\n",
       "      <td>0.743262</td>\n",
       "      <td>0.601737</td>\n",
       "      <td>0.597407</td>\n",
       "      <td>0.595674</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.051700</td>\n",
       "      <td>0.742141</td>\n",
       "      <td>0.604812</td>\n",
       "      <td>0.603968</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.606498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>0.754792</td>\n",
       "      <td>0.582197</td>\n",
       "      <td>0.579421</td>\n",
       "      <td>0.571994</td>\n",
       "      <td>0.574007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.868900</td>\n",
       "      <td>0.806123</td>\n",
       "      <td>0.602007</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.594857</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.843830</td>\n",
       "      <td>0.608418</td>\n",
       "      <td>0.607001</td>\n",
       "      <td>0.606906</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.843557</td>\n",
       "      <td>0.612696</td>\n",
       "      <td>0.612778</td>\n",
       "      <td>0.612729</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.706400</td>\n",
       "      <td>0.898429</td>\n",
       "      <td>0.612283</td>\n",
       "      <td>0.609641</td>\n",
       "      <td>0.609134</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.944040</td>\n",
       "      <td>0.601514</td>\n",
       "      <td>0.597799</td>\n",
       "      <td>0.596445</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>1.170814</td>\n",
       "      <td>0.579762</td>\n",
       "      <td>0.578244</td>\n",
       "      <td>0.573067</td>\n",
       "      <td>0.574007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.574300</td>\n",
       "      <td>1.199016</td>\n",
       "      <td>0.600153</td>\n",
       "      <td>0.585460</td>\n",
       "      <td>0.575060</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>1.162855</td>\n",
       "      <td>0.615139</td>\n",
       "      <td>0.600727</td>\n",
       "      <td>0.592869</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.523300</td>\n",
       "      <td>1.209194</td>\n",
       "      <td>0.603877</td>\n",
       "      <td>0.604073</td>\n",
       "      <td>0.602842</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.422400</td>\n",
       "      <td>1.327830</td>\n",
       "      <td>0.609501</td>\n",
       "      <td>0.609066</td>\n",
       "      <td>0.606416</td>\n",
       "      <td>0.606498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>1.788420</td>\n",
       "      <td>0.588885</td>\n",
       "      <td>0.579525</td>\n",
       "      <td>0.562157</td>\n",
       "      <td>0.570397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>1.578252</td>\n",
       "      <td>0.622290</td>\n",
       "      <td>0.620909</td>\n",
       "      <td>0.616924</td>\n",
       "      <td>0.617329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>1.494470</td>\n",
       "      <td>0.583259</td>\n",
       "      <td>0.578323</td>\n",
       "      <td>0.575068</td>\n",
       "      <td>0.584838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>1.811207</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>0.621981</td>\n",
       "      <td>0.620860</td>\n",
       "      <td>0.620939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>1.822776</td>\n",
       "      <td>0.587690</td>\n",
       "      <td>0.587342</td>\n",
       "      <td>0.584751</td>\n",
       "      <td>0.584838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>1.884333</td>\n",
       "      <td>0.587105</td>\n",
       "      <td>0.586950</td>\n",
       "      <td>0.584816</td>\n",
       "      <td>0.584838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>2.307246</td>\n",
       "      <td>0.588547</td>\n",
       "      <td>0.588806</td>\n",
       "      <td>0.588185</td>\n",
       "      <td>0.588448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>2.373297</td>\n",
       "      <td>0.630494</td>\n",
       "      <td>0.628542</td>\n",
       "      <td>0.623956</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>2.164354</td>\n",
       "      <td>0.596650</td>\n",
       "      <td>0.596832</td>\n",
       "      <td>0.595620</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>2.369590</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.619236</td>\n",
       "      <td>0.619331</td>\n",
       "      <td>0.620939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>2.632240</td>\n",
       "      <td>0.623093</td>\n",
       "      <td>0.621484</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>2.696503</td>\n",
       "      <td>0.608436</td>\n",
       "      <td>0.607393</td>\n",
       "      <td>0.607402</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>2.812868</td>\n",
       "      <td>0.612929</td>\n",
       "      <td>0.608465</td>\n",
       "      <td>0.607082</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>2.871212</td>\n",
       "      <td>0.590987</td>\n",
       "      <td>0.591054</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>0.592058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>2.911697</td>\n",
       "      <td>0.595767</td>\n",
       "      <td>0.596047</td>\n",
       "      <td>0.595409</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>3.152522</td>\n",
       "      <td>0.601088</td>\n",
       "      <td>0.599576</td>\n",
       "      <td>0.595029</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>2.984068</td>\n",
       "      <td>0.601124</td>\n",
       "      <td>0.600152</td>\n",
       "      <td>0.600131</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>3.314019</td>\n",
       "      <td>0.579034</td>\n",
       "      <td>0.577852</td>\n",
       "      <td>0.573334</td>\n",
       "      <td>0.574007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>3.048896</td>\n",
       "      <td>0.612958</td>\n",
       "      <td>0.613171</td>\n",
       "      <td>0.612992</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>3.151008</td>\n",
       "      <td>0.594068</td>\n",
       "      <td>0.593694</td>\n",
       "      <td>0.593757</td>\n",
       "      <td>0.595668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>3.240710</td>\n",
       "      <td>0.615755</td>\n",
       "      <td>0.614242</td>\n",
       "      <td>0.614186</td>\n",
       "      <td>0.617329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>3.294746</td>\n",
       "      <td>0.604759</td>\n",
       "      <td>0.603576</td>\n",
       "      <td>0.603522</td>\n",
       "      <td>0.606498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.421571</td>\n",
       "      <td>0.623944</td>\n",
       "      <td>0.624229</td>\n",
       "      <td>0.623956</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>3.447253</td>\n",
       "      <td>0.608520</td>\n",
       "      <td>0.606217</td>\n",
       "      <td>0.605787</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>3.521259</td>\n",
       "      <td>0.619413</td>\n",
       "      <td>0.618451</td>\n",
       "      <td>0.618532</td>\n",
       "      <td>0.620939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.557683</td>\n",
       "      <td>0.626975</td>\n",
       "      <td>0.626869</td>\n",
       "      <td>0.626914</td>\n",
       "      <td>0.628159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.579993</td>\n",
       "      <td>0.623060</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.621942</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>3.615534</td>\n",
       "      <td>0.606044</td>\n",
       "      <td>0.606321</td>\n",
       "      <td>0.605985</td>\n",
       "      <td>0.606498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.598749</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>3.642075</td>\n",
       "      <td>0.609031</td>\n",
       "      <td>0.605040</td>\n",
       "      <td>0.603783</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>3.739702</td>\n",
       "      <td>0.612809</td>\n",
       "      <td>0.612491</td>\n",
       "      <td>0.610063</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.652520</td>\n",
       "      <td>0.623060</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.621942</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.663055</td>\n",
       "      <td>0.615789</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.615116</td>\n",
       "      <td>0.617329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>3.700258</td>\n",
       "      <td>0.623060</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.621942</td>\n",
       "      <td>0.624549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.718408</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.740451</td>\n",
       "      <td>0.608609</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>0.608265</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.749714</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.754471</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>3.760534</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.771098</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.778780</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>3.786718</td>\n",
       "      <td>0.608609</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>0.608265</td>\n",
       "      <td>0.610108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.791927</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.796309</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.800594</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>3.805336</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.810126</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.813748</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.815935</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.817801</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.819035</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.820257</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.821281</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.821887</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.822453</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.822680</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.822790</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.822816</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.611602</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2340, training_loss=0.4399683754214555, metrics={'train_runtime': 2110.4462, 'train_samples_per_second': 35.395, 'train_steps_per_second': 1.109, 'total_flos': 37209876395328.0, 'train_loss': 0.4399683754214555, 'epoch': 30.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
