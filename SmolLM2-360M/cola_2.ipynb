{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ac762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in using your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f89ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets  = load_dataset(\"glue\", 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cff02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceTB/SmolLM2-360M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-360M\"\n",
    "\n",
    "#config.num_labels=2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers.activations import ACT2FN\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to('cuda')\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "import RoCoFT\n",
    "\n",
    "RoCoFT.PEFT(model, method='column', rank=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704a1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "# col_to_delete = ['idx']\n",
    "col_to_delete = ['question','sentence']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    prompts = [\n",
    "        f\"Sentence: {sentence} Is this sentence grammatically correct? Answer 'yes' or 'no'.\"\n",
    "        for sentence in examples[\"sentence\"]\n",
    "    ]\n",
    "    return tokenizer(prompts, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocessing_function, batched=True)\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cd4cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sentence: The more Fred is obnoxious, the less attention you should pay to him. Is this sentence grammatically correct? Answer 'yes' or 'no'.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['validation']['input_ids'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    mcc = metrics.matthews_corrcoef(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy, 'mcc': mcc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41af8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    # gradient_accumulation_steps= 8,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=100,\n",
    "    max_grad_norm = 1,\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=500,\n",
    "    label_smoothing_factor=0.1,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4207dcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10690' max='10690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10690/10690 30:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.964595</td>\n",
       "      <td>0.345638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.883300</td>\n",
       "      <td>0.761164</td>\n",
       "      <td>0.345638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.345638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.628104</td>\n",
       "      <td>0.345638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.624394</td>\n",
       "      <td>0.345638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.613100</td>\n",
       "      <td>0.615039</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.502412</td>\n",
       "      <td>0.415012</td>\n",
       "      <td>0.692234</td>\n",
       "      <td>0.041615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.614824</td>\n",
       "      <td>0.845969</td>\n",
       "      <td>0.501553</td>\n",
       "      <td>0.412058</td>\n",
       "      <td>0.692234</td>\n",
       "      <td>0.046356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.605620</td>\n",
       "      <td>0.655265</td>\n",
       "      <td>0.508955</td>\n",
       "      <td>0.432790</td>\n",
       "      <td>0.694151</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>0.607939</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>0.511729</td>\n",
       "      <td>0.434426</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.117166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.598516</td>\n",
       "      <td>0.703440</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.488601</td>\n",
       "      <td>0.706616</td>\n",
       "      <td>0.169142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.605200</td>\n",
       "      <td>0.597502</td>\n",
       "      <td>0.740759</td>\n",
       "      <td>0.528448</td>\n",
       "      <td>0.471801</td>\n",
       "      <td>0.705657</td>\n",
       "      <td>0.165518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.668432</td>\n",
       "      <td>0.565956</td>\n",
       "      <td>0.551220</td>\n",
       "      <td>0.712368</td>\n",
       "      <td>0.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.586498</td>\n",
       "      <td>0.688306</td>\n",
       "      <td>0.559609</td>\n",
       "      <td>0.537358</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.211894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.580579</td>\n",
       "      <td>0.675419</td>\n",
       "      <td>0.570614</td>\n",
       "      <td>0.558079</td>\n",
       "      <td>0.715244</td>\n",
       "      <td>0.222595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.575480</td>\n",
       "      <td>0.676114</td>\n",
       "      <td>0.606072</td>\n",
       "      <td>0.610336</td>\n",
       "      <td>0.723873</td>\n",
       "      <td>0.273356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>0.680269</td>\n",
       "      <td>0.563906</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.214665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.567197</td>\n",
       "      <td>0.691377</td>\n",
       "      <td>0.574941</td>\n",
       "      <td>0.563188</td>\n",
       "      <td>0.720038</td>\n",
       "      <td>0.239517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.558624</td>\n",
       "      <td>0.692736</td>\n",
       "      <td>0.595263</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>0.726750</td>\n",
       "      <td>0.271003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>0.567497</td>\n",
       "      <td>0.761963</td>\n",
       "      <td>0.571730</td>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.728667</td>\n",
       "      <td>0.274158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.564342</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.574670</td>\n",
       "      <td>0.554953</td>\n",
       "      <td>0.731544</td>\n",
       "      <td>0.287468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.541758</td>\n",
       "      <td>0.737810</td>\n",
       "      <td>0.590499</td>\n",
       "      <td>0.583381</td>\n",
       "      <td>0.734420</td>\n",
       "      <td>0.293405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.525096</td>\n",
       "      <td>0.763255</td>\n",
       "      <td>0.715959</td>\n",
       "      <td>0.730878</td>\n",
       "      <td>0.789070</td>\n",
       "      <td>0.476875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.517281</td>\n",
       "      <td>0.769028</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.714557</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.460262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.510090</td>\n",
       "      <td>0.762108</td>\n",
       "      <td>0.733341</td>\n",
       "      <td>0.744230</td>\n",
       "      <td>0.792905</td>\n",
       "      <td>0.494614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.511260</td>\n",
       "      <td>0.774709</td>\n",
       "      <td>0.694114</td>\n",
       "      <td>0.712521</td>\n",
       "      <td>0.786194</td>\n",
       "      <td>0.461844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.762653</td>\n",
       "      <td>0.754161</td>\n",
       "      <td>0.758068</td>\n",
       "      <td>0.796740</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.498252</td>\n",
       "      <td>0.778717</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.525303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.499647</td>\n",
       "      <td>0.791988</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>0.745134</td>\n",
       "      <td>0.804410</td>\n",
       "      <td>0.513990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.495713</td>\n",
       "      <td>0.793005</td>\n",
       "      <td>0.727748</td>\n",
       "      <td>0.746689</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.516648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.493526</td>\n",
       "      <td>0.791988</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>0.745134</td>\n",
       "      <td>0.804410</td>\n",
       "      <td>0.513990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.489552</td>\n",
       "      <td>0.796853</td>\n",
       "      <td>0.742055</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>0.487941</td>\n",
       "      <td>0.790066</td>\n",
       "      <td>0.768724</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.558383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.795033</td>\n",
       "      <td>0.747045</td>\n",
       "      <td>0.763331</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.539950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.488140</td>\n",
       "      <td>0.799201</td>\n",
       "      <td>0.739477</td>\n",
       "      <td>0.758016</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.535357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.484962</td>\n",
       "      <td>0.798118</td>\n",
       "      <td>0.746020</td>\n",
       "      <td>0.763221</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.541639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>0.770382</td>\n",
       "      <td>0.772470</td>\n",
       "      <td>0.807287</td>\n",
       "      <td>0.545093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.481809</td>\n",
       "      <td>0.791123</td>\n",
       "      <td>0.774408</td>\n",
       "      <td>0.781685</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.565283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.508758</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>0.695728</td>\n",
       "      <td>0.717257</td>\n",
       "      <td>0.796740</td>\n",
       "      <td>0.491948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.474900</td>\n",
       "      <td>0.484101</td>\n",
       "      <td>0.796394</td>\n",
       "      <td>0.737231</td>\n",
       "      <td>0.755547</td>\n",
       "      <td>0.810163</td>\n",
       "      <td>0.530335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.480227</td>\n",
       "      <td>0.795765</td>\n",
       "      <td>0.751869</td>\n",
       "      <td>0.767302</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.545872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.479636</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.758412</td>\n",
       "      <td>0.772173</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.552625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>0.798049</td>\n",
       "      <td>0.751704</td>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.547795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.491387</td>\n",
       "      <td>0.806249</td>\n",
       "      <td>0.718989</td>\n",
       "      <td>0.740606</td>\n",
       "      <td>0.806328</td>\n",
       "      <td>0.517939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.484511</td>\n",
       "      <td>0.798619</td>\n",
       "      <td>0.725005</td>\n",
       "      <td>0.745157</td>\n",
       "      <td>0.806328</td>\n",
       "      <td>0.518423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.482477</td>\n",
       "      <td>0.796899</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.750731</td>\n",
       "      <td>0.808245</td>\n",
       "      <td>0.524390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>0.477160</td>\n",
       "      <td>0.797585</td>\n",
       "      <td>0.758246</td>\n",
       "      <td>0.772643</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.554437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.477560</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.768528</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.552015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>0.476013</td>\n",
       "      <td>0.786603</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.773952</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.551101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.486533</td>\n",
       "      <td>0.803561</td>\n",
       "      <td>0.732768</td>\n",
       "      <td>0.752984</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.531637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.476117</td>\n",
       "      <td>0.790066</td>\n",
       "      <td>0.768724</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.558383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.478563</td>\n",
       "      <td>0.795765</td>\n",
       "      <td>0.751869</td>\n",
       "      <td>0.767302</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.545872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.484251</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.734125</td>\n",
       "      <td>0.752499</td>\n",
       "      <td>0.808245</td>\n",
       "      <td>0.525060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>0.480065</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>0.744799</td>\n",
       "      <td>0.760904</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.535041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.478810</td>\n",
       "      <td>0.797168</td>\n",
       "      <td>0.755834</td>\n",
       "      <td>0.770710</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.551456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.459100</td>\n",
       "      <td>0.477334</td>\n",
       "      <td>0.786603</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.773952</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.551101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.792642</td>\n",
       "      <td>0.766840</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.558886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>0.477084</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.758412</td>\n",
       "      <td>0.772173</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.552625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.476193</td>\n",
       "      <td>0.791780</td>\n",
       "      <td>0.772689</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.564146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.477847</td>\n",
       "      <td>0.794559</td>\n",
       "      <td>0.753588</td>\n",
       "      <td>0.768309</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.546614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>0.482311</td>\n",
       "      <td>0.801375</td>\n",
       "      <td>0.744995</td>\n",
       "      <td>0.763095</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.543453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.489600</td>\n",
       "      <td>0.476097</td>\n",
       "      <td>0.791865</td>\n",
       "      <td>0.754613</td>\n",
       "      <td>0.768350</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.545207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.475814</td>\n",
       "      <td>0.796463</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.555230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.477112</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.760990</td>\n",
       "      <td>0.773599</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.553907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.476886</td>\n",
       "      <td>0.794440</td>\n",
       "      <td>0.756859</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.550017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.483396</td>\n",
       "      <td>0.800029</td>\n",
       "      <td>0.738618</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.535135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.479144</td>\n",
       "      <td>0.792361</td>\n",
       "      <td>0.739115</td>\n",
       "      <td>0.756289</td>\n",
       "      <td>0.809204</td>\n",
       "      <td>0.528802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.476552</td>\n",
       "      <td>0.796162</td>\n",
       "      <td>0.754281</td>\n",
       "      <td>0.769261</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.548848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.477136</td>\n",
       "      <td>0.794141</td>\n",
       "      <td>0.751176</td>\n",
       "      <td>0.766351</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.543622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.477391</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.747904</td>\n",
       "      <td>0.763855</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.540288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.478988</td>\n",
       "      <td>0.794388</td>\n",
       "      <td>0.742221</td>\n",
       "      <td>0.759287</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.534067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.474158</td>\n",
       "      <td>0.798441</td>\n",
       "      <td>0.766342</td>\n",
       "      <td>0.778798</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.474015</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.473800</td>\n",
       "      <td>0.474981</td>\n",
       "      <td>0.793983</td>\n",
       "      <td>0.754447</td>\n",
       "      <td>0.768806</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.547004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>0.473777</td>\n",
       "      <td>0.791275</td>\n",
       "      <td>0.778538</td>\n",
       "      <td>0.784267</td>\n",
       "      <td>0.819751</td>\n",
       "      <td>0.569671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.477741</td>\n",
       "      <td>0.792729</td>\n",
       "      <td>0.747211</td>\n",
       "      <td>0.762906</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.538018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.479012</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.741362</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.533770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.477247</td>\n",
       "      <td>0.793744</td>\n",
       "      <td>0.748764</td>\n",
       "      <td>0.764375</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.540639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.473382</td>\n",
       "      <td>0.792868</td>\n",
       "      <td>0.770111</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.562519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.429500</td>\n",
       "      <td>0.475871</td>\n",
       "      <td>0.798172</td>\n",
       "      <td>0.757387</td>\n",
       "      <td>0.772156</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.554060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.474549</td>\n",
       "      <td>0.794397</td>\n",
       "      <td>0.760131</td>\n",
       "      <td>0.773128</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.553468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.473874</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>0.762015</td>\n",
       "      <td>0.773581</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.552689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.473770</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.774949</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.554182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.474146</td>\n",
       "      <td>0.790590</td>\n",
       "      <td>0.763734</td>\n",
       "      <td>0.774497</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.553673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.475566</td>\n",
       "      <td>0.795411</td>\n",
       "      <td>0.761684</td>\n",
       "      <td>0.774551</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.556073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.475458</td>\n",
       "      <td>0.796939</td>\n",
       "      <td>0.762377</td>\n",
       "      <td>0.775504</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.558247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.473761</td>\n",
       "      <td>0.792642</td>\n",
       "      <td>0.766840</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.558886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.794440</td>\n",
       "      <td>0.756859</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.550017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.475285</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.760824</td>\n",
       "      <td>0.774080</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.555645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.474730</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.765649</td>\n",
       "      <td>0.777844</td>\n",
       "      <td>0.819751</td>\n",
       "      <td>0.561713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>0.798441</td>\n",
       "      <td>0.766342</td>\n",
       "      <td>0.778798</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>0.473952</td>\n",
       "      <td>0.792041</td>\n",
       "      <td>0.764427</td>\n",
       "      <td>0.775445</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.555783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.475546</td>\n",
       "      <td>0.796463</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.555230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.475625</td>\n",
       "      <td>0.796463</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.555230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.475572</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.758412</td>\n",
       "      <td>0.772173</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.552625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.474903</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.475097</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.475212</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.475631</td>\n",
       "      <td>0.796463</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.555230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.475850</td>\n",
       "      <td>0.794440</td>\n",
       "      <td>0.756859</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.815916</td>\n",
       "      <td>0.550017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.482400</td>\n",
       "      <td>0.475327</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.475032</td>\n",
       "      <td>0.797433</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>0.819751</td>\n",
       "      <td>0.561274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.475082</td>\n",
       "      <td>0.797433</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>0.819751</td>\n",
       "      <td>0.561274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>0.475210</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.475261</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.475280</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.475279</td>\n",
       "      <td>0.798952</td>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>0.563442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/miniconda3/envs/emnlp_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10690, training_loss=0.5015196144525084, metrics={'train_runtime': 1828.4217, 'train_samples_per_second': 46.767, 'train_steps_per_second': 5.847, 'total_flos': 15640108879572.0, 'train_loss': 0.5015196144525084, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
